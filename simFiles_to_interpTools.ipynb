{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create input files for interpolation tools in Matlab or Python from Rain Simulator output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This script takes the outputs of the rain simulator and combines them to create 2 .csv files which are compatible to the code of IE algorithm in Matlab.\n",
    "* The names of the output files must be: `sim_out_0.csv`, `sim_out_1.csv`... `sim_out_N.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "in_path = '/Volumes/0543970348/IE_directory/aviv/test/'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import sys\n",
    "# the equivalent to \"Add to path\" in Matlab\n",
    "sys.path.append(\"/Users/adameshel/Documents/Python_scripts/wrf_hydro_pyscripts/\") \n",
    "from helper_functions import split_at\n",
    "\n",
    "num_of_sim_timestamps = len(glob.glob(in_path + 'sim_out_000_*_Z.csv'))\n",
    "num_of_link_iter = len(glob.glob(in_path + 'sim_out_*_000_Z.csv'))\n",
    "\n",
    "f = open(in_path + \"/list_of_runParam.txt\", \"r\")\n",
    "for line in f:\n",
    "    if 'quantization:' in line:\n",
    "        quantization = float(line.split()[-2])\n",
    "        break\n",
    "f.close()\n",
    "\n",
    "for j in range(num_of_link_iter):\n",
    "    # create the dataframe by an example of the first sim_out files for every j (links setting)\n",
    "    start_date = '2016-01-23 12:00:00'\n",
    "    jj = split_at(str(format(j/1000, '.3f')),'.',1)[-1]\n",
    "    example_csv = pd.read_csv(str(in_path + 'sim_out_' + str(jj) + '_000.csv'))\n",
    "    timestamps = pd.date_range(start=start_date, \n",
    "                               periods=num_of_sim_timestamps, \n",
    "                               freq='H')\n",
    "    df_simData = pd.DataFrame(index=timestamps, \n",
    "                              columns=example_csv.Link_num.values)\n",
    "    df_simData.index.rename('time', \n",
    "                            inplace=True)\n",
    "\n",
    "    # Create a liks-rain intensity for every i (rain snapshots)\n",
    "    for i in range(num_of_sim_timestamps):  \n",
    "        ii = split_at(str(format(i/1000, '.3f')),'.',1)[-1]\n",
    "        csv_str = str(in_path + 'sim_out_' + str(jj) + '_' + str(ii) + '.csv')\n",
    "        df_temp = pd.read_csv(csv_str)\n",
    "        # compute df_temp.Rain1 externally of rainSim (Hagit's request)\n",
    "        df_temp['my_rain1'] = (df_temp.A_1.values.clip(min=0)/(df_temp.ITU_a1.values*\\\n",
    "                                                              df_temp.Length.values))**\\\n",
    "                                                            (1/df_temp.ITU_b1.values)\n",
    "        d = dict(zip(df_temp.Link_num, round(df_temp.my_rain1, 3)))\n",
    "        df_simData.iloc[i] = pd.Series(d)\n",
    "    df_simData.to_csv(in_path + 'links_rainrate_mm_h_' + str(jj) + '.csv')\n",
    "    \n",
    "    # create metadata df for every j\n",
    "    df_links_lat_lon = pd.DataFrame(index=example_csv['Link_num'], \n",
    "                                    columns= ['lat1', 'lon1', 'lat2', 'lon2', 'a', 'b', 'L', 'noise'])\n",
    "    df_links_lat_lon.index.name = 'link'\n",
    "\n",
    "    df_links_lat_lon['lat1'] = example_csv['ya'].values\n",
    "    df_links_lat_lon['lon1'] = example_csv['xa'].values\n",
    "    df_links_lat_lon['lat2'] = example_csv['yb'].values\n",
    "    df_links_lat_lon['lon2'] = example_csv['xb'].values\n",
    "    df_links_lat_lon['a'] = example_csv['ITU_a1'].values\n",
    "    df_links_lat_lon['b'] = example_csv['ITU_b1'].values\n",
    "    df_links_lat_lon['L'] = example_csv['Length'].values\n",
    "    df_links_lat_lon['noise'] = quantization # 0.3\n",
    "\n",
    "    df_links_lat_lon.to_csv(in_path + 'links_metadata_' + str(jj) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../wrf_hydro_pyscripts/\")\n",
    "from helper_functions import restartkernel\n",
    "\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this only if you used the output of the script `create_rgs_from_links.ipynb` in RainSim\n",
    "### Artificial net of RG from a net of links\n",
    "This is needed for Hagit's paper where the performances of a non-real RG net is compared with a link net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # create fake rain gauges files to run IE with links only\n",
    "# timestamps = pd.date_range(start=start_date, \n",
    "#                            periods=num_of_sim_timestamps, \n",
    "#                            freq='H')\n",
    "# df_rg_fake = pd.DataFrame(index=timestamps, \n",
    "#                           columns=['gauge1', 'gauge2'])\n",
    "# df_rg_fake.index.rename('time', \n",
    "#                       inplace=True)\n",
    "# df_rg_fake['gauge1'] = np.zeros([len(timestamps),1])\n",
    "# df_rg_fake['gauge2'] = np.zeros([len(timestamps),1])\n",
    "\n",
    "# df_rg_fake.to_csv(in_path + 'dataRg_fake.csv')\n",
    "\n",
    "\n",
    "\n",
    "# # fake metadata file\n",
    "# df_rg_lat_lon_fake = pd.DataFrame(index= [0,1], \n",
    "#                                   columns= ['lat', 'lon', 'name', 'noise'])\n",
    "# df_rg_lat_lon_fake.index.name = 'gauge'\n",
    "# df_rg_lat_lon_fake['name'] = ['gauge1', 'gauge2']\n",
    "# df_rg_lat_lon_fake['lat'] = [39.00000, 49.00000]\n",
    "# df_rg_lat_lon_fake['lon'] = [59.00000, 69.00000]\n",
    "# df_rg_lat_lon_fake['noise'] = 0.1\n",
    "\n",
    "# df_rg_lat_lon_fake.to_csv(in_path + 'rg_lat_lon_fake.csv')\n",
    "\n",
    "\n",
    "\n",
    "# df8 = df_temp[np.abs((df_temp['xa'] - df_temp['xb']) < 1e-6) & np.abs((df_temp['ya'] - df_temp['yb']) < 1e-6)]\n",
    "\n",
    "\n",
    "in_path = '/Volumes/0543970348/IE_directory/22022016_24h_data/test/'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "num_of_sim_timestamps = len(glob.glob(in_path + 'sim_out_0_*_Z.csv'))\n",
    "num_of_link_iter = len(glob.glob(in_path + 'sim_out_*_0_Z.csv'))\n",
    "\n",
    "for j in range(num_of_link_iter):\n",
    "    # create the dataframe by an example of the first sim_out files for every j (links setting)\n",
    "    start_date = '2016-01-23 12:00:00'\n",
    "    example_csv = pd.read_csv(str(in_path + 'sim_out_' + str(j) + '_0.csv'))\n",
    "    example_csv_links = example_csv[(example_csv['xa'] - example_csv['xb'] == 0) & \\\n",
    "                                    (example_csv['ya'] - example_csv['yb'] == 0)]\n",
    "    example_csv_rg = example_csv[(example_csv['xa'] - example_csv['xb'] == 0) & \\\n",
    "                                 (example_csv['ya'] - example_csv['yb'] == 0)]\n",
    "    example_csv_rg.Link_num = range(len(example_csv_rg))\n",
    "    timestamps = pd.date_range(start=start_date, \n",
    "                               periods=num_of_sim_timestamps, \n",
    "                               freq='H')\n",
    "    df_simData_links = pd.DataFrame(index=timestamps, \n",
    "                              columns=example_csv_links.Link_num.values)\n",
    "    df_simData_links.index.rename('time', \n",
    "                            inplace=True)\n",
    "    df_simData_rg = pd.DataFrame(index=timestamps, \n",
    "                              columns=example_csv_rg.Link_num.values)\n",
    "    df_simData_rg.index.rename('time', \n",
    "                            inplace=True)\n",
    "\n",
    "    # Create a liks-rain intensity for every i (rain snapshots)\n",
    "    for i in range(num_of_sim_timestamps):   \n",
    "        csv_str = str(in_path + 'sim_out_' + str(j) + '_' + str(i) + '.csv')\n",
    "        df_temp = pd.read_csv(csv_str)\n",
    "        \n",
    "        df_temp_links = example_csv[(example_csv['xa'] - example_csv['xb'] == 0) & \\\n",
    "                                    (example_csv['ya'] - example_csv['yb'] == 0)]\n",
    "        df_temp_rg = example_csv[(example_csv['xa'] - example_csv['xb'] == 0) & \\\n",
    "                                 (example_csv['ya'] - example_csv['yb'] == 0)]\n",
    "        \n",
    "        d_links = dict(zip(df_temp_links.Link_num, round(df_temp_links.Rain1, 3)))\n",
    "#         d_rg = dict(zip(df_temp_rg.Link_num, round(df_temp_rg.A_1, 3)))\n",
    "#         df_simData_links.iloc[i] = pd.Series(d_links)\n",
    "#         df_simData_rg.iloc[i] = pd.Series(d_rg)\n",
    "        \n",
    "#     df_simData_links.to_csv(in_path + 'links_rainrate_mm_h_' + str(j) + '.csv')\n",
    "#     df_simData_rg.to_csv(in_path + 'rg_rainrate_mm_h_' + str(j) + '.csv')\n",
    "\n",
    "    \n",
    "#     # create metadata df for every j\n",
    "#     df_links_lat_lon = pd.DataFrame(index=example_csv['Link_num'], \n",
    "#                                     columns= ['lat1', 'lon1', 'lat2', 'lon2', 'a', 'b', 'L', 'noise'])\n",
    "#     df_links_lat_lon.index.name = 'link'\n",
    "\n",
    "#     df_links_lat_lon['lat1'] = example_csv['ya'].values\n",
    "#     df_links_lat_lon['lon1'] = example_csv['xa'].values\n",
    "#     df_links_lat_lon['lat2'] = example_csv['yb'].values\n",
    "#     df_links_lat_lon['lon2'] = example_csv['xb'].values\n",
    "#     df_links_lat_lon['a'] = example_csv['ITU_a1'].values\n",
    "#     df_links_lat_lon['b'] = example_csv['ITU_b1'].values\n",
    "#     df_links_lat_lon['L'] = example_csv['Length'].values\n",
    "#     df_links_lat_lon['noise'] = 0.1\n",
    "\n",
    "#     df_links_lat_lon.to_csv(in_path + 'links_metadata_' + str(j) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not in use untill rain gauses data is ordered and integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # create fake rain gauges files to run IE with links only\n",
    "# timestamps = pd.date_range(start=start_date, \n",
    "#                            periods=num_of_sim_timestamps, \n",
    "#                            freq='H')\n",
    "# df_rg_fake = pd.DataFrame(index=timestamps, \n",
    "#                           columns=['gauge1', 'gauge2'])\n",
    "# df_rg_fake.index.rename('time', \n",
    "#                       inplace=True)\n",
    "# df_rg_fake['gauge1'] = np.zeros([len(timestamps),1])\n",
    "# df_rg_fake['gauge2'] = np.zeros([len(timestamps),1])\n",
    "\n",
    "# df_rg_fake.to_csv(in_path + 'dataRg_fake.csv')\n",
    "\n",
    "\n",
    "\n",
    "# # fake metadata file\n",
    "# df_rg_lat_lon_fake = pd.DataFrame(index= [0,1], \n",
    "#                                   columns= ['lat', 'lon', 'name', 'noise'])\n",
    "# df_rg_lat_lon_fake.index.name = 'gauge'\n",
    "# df_rg_lat_lon_fake['name'] = ['gauge1', 'gauge2']\n",
    "# df_rg_lat_lon_fake['lat'] = [39.00000, 49.00000]\n",
    "# df_rg_lat_lon_fake['lon'] = [59.00000, 69.00000]\n",
    "# df_rg_lat_lon_fake['noise'] = 0.1\n",
    "\n",
    "# df_rg_lat_lon_fake.to_csv(in_path + 'rg_lat_lon_fake.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data in directory is now ready to be used in IE code (`imap.m` in Matlab)\n",
    "* no need to go through `imapFileReader.m`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
